#!/usr/bin/python

from nltk import sent_tokenize
import re

opt = {
    "gene": {
        "target_text": re.escape('$_TARGET_GENE_$'),
        "value": 1
    },
    "variation": {
        "target_text": re.escape('$_TARGET_VARIATION_$'),
        "value": 1
    },
    "window_size": 1
}

for field in ['test', 'train']:
    sub_text_file = open('../res/%s/%s.sub-text.window_%s' % (field, field, opt['window_size']), 'w')

    for row in open('../res/%s/%s.text.alias' % (field, field), 'r'):
        if not re.match('ID', row):
            row_id, text = row.split('||')

            total_sentences = []
            reserved_paragraphs = []

            for _stc in sent_tokenize(text.rstrip()):
                while True:
                    stc_end = re.search('\s\.[A-Z]\w+', _stc)
                    stc = _stc[:stc_end.start() + 2] if stc_end else _stc

                    if len(re.findall(opt['variation']['target_text'], stc)):
                        stcid = len(total_sentences)
                        p_start_id = stcid - opt['window_size'] / 2
                        p_end_id = stcid + opt['window_size'] / 2 + 1

                        reserved_paragraphs.append([p_start_id, p_end_id])

                    total_sentences.append(stc)

                    if not stc_end:
                        break

                    _stc = _stc[stc_end.start() + 2:]

            if not len(reserved_paragraphs):
                reserved_paragraphs.append([0, min(len(total_sentences), opt['window_size'])])

            row = row_id + '||'

            for p in reserved_paragraphs:
                for stcid in range(p[0], p[1]):
                    if stcid < 0 or stcid >= len(total_sentences):
                        continue

                    row += total_sentences[stcid]

                    if 1 < opt['window_size']:
                        row += ' &_SENTENCE_END_& '
                row += ' &_PARAGRAPH_END_& '

            row += '\n'

        sub_text_file.write(row)
    sub_text_file.close()
